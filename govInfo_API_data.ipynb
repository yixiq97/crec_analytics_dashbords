{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57dfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bbb1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "from github import InputGitTreeElement\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0e6a4",
   "metadata": {},
   "source": [
    "# GET DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c0695",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498901c3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_CREC_packages(pageSize, startDate= '2018-07-01T00:00:00'): #from collections\n",
    "    apiKey = 'RjhPNKjGtGp1AbN4Ilb1jbrhCO9IBvqqLvRKsA1e'\n",
    "    api_url = f'https://api.govinfo.gov/collections/CREC/{startDate}Z?offset=0&pageSize={pageSize}&api_key={apiKey}'\n",
    "    data = requests.get(api_url).json()\n",
    "    data = data['packages']\n",
    "    return data\n",
    "\n",
    "def ## Endpoints (TBD)get_CREC_summary(packageLink):   #packageLink retrieved from package table\n",
    "    apiKey = 'RjhPNKjGtGp1AbN4Ilb1jbrhCO9IBvqqLvRKsA1e'\n",
    "    url = packageLink + f'?api_key={apiKey}'\n",
    "    record = requests.get(url).json()\n",
    "    return record #one record each time\n",
    "    \n",
    "def get_CREC_granules(granulesLink):  # granulesLink retrieved from the summary table, get_CREC_summary(packageLink)['granulesLink']\n",
    "    apiKey = 'RjhPNKjGtGp1AbN4Ilb1jbrhCO9IBvqqLvRKsA1e'\n",
    "    url = granulesLink + f'&api_key={apiKey}'\n",
    "    data = requests.get(url).json()\n",
    "    count = data['count']\n",
    "    granules = data['granules']\n",
    "    return count,granules\n",
    "\n",
    "# General Version: \n",
    "def get_CREC_granuleInfo(granuleLink): # granuleLink retrieved from the granule table\n",
    "    apiKey = 'RjhPNKjGtGp1AbN4Ilb1jbrhCO9IBvqqLvRKsA1e'\n",
    "    url = granuleLink + f'?api_key={apiKey}'\n",
    "    data = requests.get(url).json()\n",
    "    return data\n",
    "\n",
    "def txt_download(granule_json):\n",
    "    apiKey = 'RjhPNKjGtGp1AbN4Ilb1jbrhCO9IBvqqLvRKsA1e'\n",
    "    url = granule_json['download']['txtLink'] + f'?api_key={apiKey}'\n",
    "    raw_text = requests.get(url).text\n",
    "    \n",
    "    soup = BeautifulSoup(raw_text)\n",
    "    text_body = soup.find('body').get_text()\n",
    "    return text_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f4068",
   "metadata": {},
   "source": [
    "## Endpoints (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Granule_Titles():\n",
    "    def __init__(self,granules_data):\n",
    "        self.all_granules = granules_data\n",
    "        self.S_H_E_granules = [i for i in granules_data if i['granuleClass'] != 'DAILYDIGEST']\n",
    "        \n",
    "    def S_H_E_titles_txt(self):\n",
    "        titles_txt = ''\n",
    "        for granule in self.S_H_E_granules:\n",
    "            granule_title = granule['title']\n",
    "            titles_txt += granule_title\n",
    "            titles_txt += '\\n'\n",
    "        return titles_txt\n",
    "    \n",
    "    def S_H_E_titles_df(self):\n",
    "        titles_df = pd.DataFrame()\n",
    "        titles_df['title'] = [i['title'] for i in self.all_senate]\n",
    "        titles_df['granuleId'] = [i['granuleId'] for i in self.all_senate]\n",
    "        titles_df['granuleClass'] = [i['granuleClass'] for i in self.all_senate]\n",
    "        return titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "60d35e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyDigest():\n",
    "    def __init__(self,granules_data):\n",
    "        self.all_granules = granules_data\n",
    "        self.all_digests = [i for i in granules_data if i['granuleClass'] == 'DAILYDIGEST']\n",
    "        self.today_digests = self.all_digests[2:]\n",
    "        \n",
    "    #def get_titles():\n",
    "    #def get_class():\n",
    "\n",
    "    def today_digest_text(self):\n",
    "        today_text = ''\n",
    "        for record in self.today_digests:\n",
    "            link = record['granuleLink']\n",
    "            dailyDigest_json = get_CREC_granuleInfo(link)\n",
    "            text_record = txt_download(dailyDigest_json)\n",
    "            today_text += text_record\n",
    "        return today_text\n",
    "    \n",
    "    def today_digest_df(self):\n",
    "        today_df = pd.DataFrame()\n",
    "        today_df['title'] = [i['title'] for i in self.today_digests]\n",
    "        content = []\n",
    "        for record in self.today_digests:\n",
    "            link = record['granuleLink']\n",
    "            dailyDigest_json = get_CREC_granuleInfo(link)\n",
    "            text_record = txt_download(dailyDigest_json)\n",
    "            content.append(text_record)\n",
    "        today_df['content'] = content\n",
    "        return today_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f89bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Senate_House():\n",
    "    def __init__(self,granules_data):\n",
    "        self.all_granules = granules_data\n",
    "        self.all_senate = [i for i in granules_data if i['granuleClass'] == 'SENATE']\n",
    "        self.all_house = [i for i in granules_data if i['granuleClass'] == 'HOUSE']\n",
    "    \n",
    "    def today_Senate_df(self): \n",
    "        today_df = pd.DataFrame()\n",
    "        today_df['title'] = [i['title'] for i in self.all_senate]\n",
    "        today_df['granuleId'] = [i['granuleId'] for i in self.all_senate]\n",
    "        content = []\n",
    "        for record in self.today_digests:\n",
    "            link = record['granuleLink']\n",
    "            dailyDigest_json = get_CREC_granuleInfo(link)\n",
    "            text_record = txt_download(dailyDigest_json)\n",
    "            content.append(text_record)\n",
    "        today_df['content'] = content\n",
    "        return today_df        \n",
    "        \n",
    "    def today_House_df(self): \n",
    "        today_df = pd.DataFrame()\n",
    "        today_df['title'] = [i['title'] for i in self.all_house]\n",
    "        today_df['granuleId'] = [i['granuleId'] for i in self.all_house]\n",
    "        content = []\n",
    "        for record in self.today_digests:\n",
    "            link = record['granuleLink']\n",
    "            dailyDigest_json = get_CREC_granuleInfo(link)\n",
    "            text_record = txt_download(dailyDigest_json)\n",
    "            content.append(text_record)\n",
    "        today_df['content'] = content\n",
    "        return today_df        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8446a",
   "metadata": {},
   "source": [
    "# EXPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee57dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_granules_table = pd.DataFrame()\n",
    "for table in names_of_granules_table:\n",
    "    target_granules = eval(table)\n",
    "    all_granules_table = pd.concat([all_granules_table,target_granules])\n",
    "all_granules_table_csv = all_granules_table.to_csv(sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ceb920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_granules_table_csv = []\n",
    "for name_of_granules_table in names_of_granules_table:\n",
    "    names[ name_of_granules_table+'_csv'] = eval(name_of_granules_table).to_csv(sep=',', index=False)\n",
    "    names_of_granules_table_csv.append(name_of_granules_table+'_csv')\n",
    "names_of_granules_table_csv\n",
    "granule_names = [i[:-3]+'.csv' for i in names_of_granules_table]\n",
    "granules_table_csv = [eval(name_of_granules_table_csv) for name_of_granules_table_csv in names_of_granules_table_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce22ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_granules_table.to_csv('all_granules_table.csv',sep=',', index=False) # too large to upload to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a98b2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/61109527/how-to-load-python-dataframe-on-github-repository-as-a-csv-file\n",
    "#https://stackoverflow.com/questions/50071841/how-to-push-local-files-to-github-using-python-or-post-a-commit-via-python/50072113#50072113\n",
    "user = \"yixiq97\"\n",
    "password = ##########\n",
    "\n",
    "def updategitfiles(file_names,file_list,userid,pwd,Repo,branch,commit_message =\"\"):\n",
    "    if commit_message == \"\":\n",
    "        commit_message = \"Data Updated - \"+ datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    g = Github(userid,pwd)\n",
    "    repo = g.get_user().get_repo(Repo)\n",
    "    master_ref = repo.get_git_ref(\"heads/\"+branch)\n",
    "    master_sha = master_ref.object.sha\n",
    "    base_tree = repo.get_git_tree(master_sha)\n",
    "    element_list = list()\n",
    "    for i in range(0,len(file_list)):\n",
    "        element = InputGitTreeElement(file_names[i], '100644', 'blob', file_list[i])\n",
    "        element_list.append(element)\n",
    "    tree = repo.create_git_tree(element_list, base_tree)\n",
    "    parent = repo.get_git_commit(master_sha)\n",
    "    commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "    master_ref.edit(commit.sha)\n",
    "    print('Update complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e089bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n",
      "granule texts collected\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # get packagelink list from CREC collection data\n",
    "    collection_json = get_CREC_packages(40)\n",
    "    collection_attr = list(collection_json[0].keys())\n",
    "    packageLinks = [r['packageLink'] for r in collection_json]\n",
    "    collection_df = pd.DataFrame(collection_json)[['packageId','dateIssued','title','lastModified']]\n",
    "    \n",
    "    \n",
    "    # get summary of each CERC record, in 1:1 relationship\n",
    "    summary_data = [get_CREC_summary(packageLink) for packageLink in packageLinks]\n",
    "    summary_attr = list(summary_data[0].keys())\n",
    "    granulesLinks = [r['granulesLink'] for r in summary_data]\n",
    "    record_info_df = pd.DataFrame(summary_data)[['packageId','detailsLink','pages','governmentAuthor1','category']]\n",
    "    \n",
    "    \n",
    "    # get granule contents of each CERC record, in 1:M relationship\n",
    "    granules_relation = [(granulesLink,get_CREC_granules(granulesLink)[0],get_CREC_granules(granulesLink)[1]) \n",
    "                         for granulesLink in granulesLinks]    \n",
    "    granules_backward_mapping = dict([(r['granulesLink'],r['packageId']) for r in summary_data])\n",
    "    names = globals()\n",
    "    num_of_granules_table = 0\n",
    "    names_of_granules_table = []\n",
    "    for granules in granules_relation:\n",
    "        gran_link = granules[0]\n",
    "        pack_id = granules_backward_mapping[gran_link]\n",
    "        pack_id_formatted = pack_id.replace('-','')\n",
    "        names['granules_%s_df' % pack_id_formatted] = pd.DataFrame(granules[2])\n",
    "        eval('granules_%s_df' % pack_id_formatted)['packageId'] = pack_id\n",
    "        names_of_granules_table.append('granules_%s_df' % pack_id_formatted)\n",
    "        # return to table i: eval(names_of_granules_table[i])\n",
    "        num_of_granules_table += 1\n",
    "    granules_count_df=pd.DataFrame(granules_relation,columns = ['granulesLink','granulesCount','json_file'])[['granulesLink','granulesCount']]\n",
    "    package_granule_df = pd.DataFrame.from_dict(granules_backward_mapping,orient = 'index',columns = ['packageId'])\n",
    "    package_granule_df = package_granule_df.reset_index().rename(columns = {'index':'granulesLink'})    \n",
    "    \n",
    "    \n",
    "    # get granule contents of each CERC record\n",
    "    for table in names_of_granules_table:\n",
    "        title_content = []\n",
    "        for link in eval(table)['granuleLink']:\n",
    "            link_json = get_CREC_granuleInfo(link)\n",
    "            title_content.append(txt_download(link_json))\n",
    "        eval(table)['content'] = title_content\n",
    "        print('granule texts collected')\n",
    "    \n",
    "\n",
    "    # Join(merge) and get original datatables\n",
    "    CREC_summary = pd.merge(collection_df,record_info_df,on = 'packageId')\n",
    "    CREC_summary['pages'] = CREC_summary.pages.astype('int64')\n",
    "    CREC_granules =  pd.merge(pd.merge(collection_df,package_granule_df,on = 'packageId'),\n",
    "                              granules_count_df,on = 'granulesLink')\n",
    "    \n",
    "    # update to github\n",
    "    CREC_summary_csv = CREC_summary.to_csv(sep=',', index=False)\n",
    "    CREC_granules_csv = CREC_granules.to_csv(sep=',', index=False)\n",
    "\n",
    "    updategitfiles(['CREC_summary.csv','CREC_granules_summary.csv'],\n",
    "                   [CREC_summary_csv,CREC_granules_csv],\n",
    "                   user,password,\n",
    "                   'API_data','main')\n",
    "    #updategitfiles(granule_names,names_of_granules_table_csv,user,password,'API_data','main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28817263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "771.1px",
    "left": "218.988px",
    "top": "136.991px",
    "width": "278.646px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
